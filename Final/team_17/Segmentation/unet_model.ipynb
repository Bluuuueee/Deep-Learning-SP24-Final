{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5UHNDoj4mhiP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        # if you have padding issues, see\n",
        "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
        "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZfmFQpqHmrQb"
      },
      "outputs": [],
      "source": [
        "\"\"\" Full assembly of the parts to form the complete network \"\"\"\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = (DoubleConv(n_channels, 64))\n",
        "        self.down1 = (Down(64, 128))\n",
        "        self.down2 = (Down(128, 256))\n",
        "        self.down3 = (Down(256, 512))\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = (Down(512, 1024 // factor))\n",
        "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
        "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
        "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
        "        self.up4 = (Up(128, 64, bilinear))\n",
        "        self.outc = (OutConv(64, n_classes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits\n",
        "\n",
        "    def use_checkpointing(self):\n",
        "        self.inc = torch.utils.checkpoint(self.inc)\n",
        "        self.down1 = torch.utils.checkpoint(self.down1)\n",
        "        self.down2 = torch.utils.checkpoint(self.down2)\n",
        "        self.down3 = torch.utils.checkpoint(self.down3)\n",
        "        self.down4 = torch.utils.checkpoint(self.down4)\n",
        "        self.up1 = torch.utils.checkpoint(self.up1)\n",
        "        self.up2 = torch.utils.checkpoint(self.up2)\n",
        "        self.up3 = torch.utils.checkpoint(self.up3)\n",
        "        self.up4 = torch.utils.checkpoint(self.up4)\n",
        "        self.outc = torch.utils.checkpoint(self.outc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dz0ATI19m1Lg"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "from functools import lru_cache\n",
        "from functools import partial\n",
        "from itertools import repeat\n",
        "from multiprocessing import Pool\n",
        "from os import listdir\n",
        "from os.path import splitext, isfile, join\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def load_image(filename):\n",
        "    ext = splitext(filename)[1]\n",
        "    if ext == '.npy':\n",
        "        return Image.fromarray(np.load(filename))\n",
        "    elif ext in ['.pt', '.pth']:\n",
        "        return Image.fromarray(torch.load(filename).numpy())\n",
        "    else:\n",
        "        return Image.open(filename)\n",
        "\n",
        "\n",
        "def unique_mask_values(idx, mask_dir, mask_suffix):\n",
        "    mask_file = list(mask_dir.glob(idx + mask_suffix + '.npy'))[0]\n",
        "    mask = np.asarray(load_image(mask_file))\n",
        "    if mask.ndim == 2:\n",
        "        return np.unique(mask)\n",
        "    elif mask.ndim == 3:\n",
        "        mask = mask.reshape(-1, mask.shape[-1])\n",
        "        return np.unique(mask, axis=0)\n",
        "    else:\n",
        "        raise ValueError(f'Loaded masks should have 2 or 3 dimensions, found {mask.ndim}')\n",
        "\n",
        "\n",
        "class BasicDataset(Dataset):\n",
        "    def __init__(self, images_dir: str, mask_dir: str, scale: float = 1.0, mask_suffix: str = ''):\n",
        "        self.images_dir = Path(images_dir)\n",
        "        self.mask_dir = Path(mask_dir)\n",
        "        assert 0 < scale <= 1, 'Scale must be between 0 and 1'\n",
        "        self.scale = scale\n",
        "        self.mask_suffix = mask_suffix\n",
        "\n",
        "        self.ids = [splitext(file)[0] for file in listdir(images_dir)]\n",
        "        if not self.ids:\n",
        "            raise RuntimeError(f'No input file found in {images_dir}, make sure you put your images there')\n",
        "\n",
        "        logging.info(f'Creating dataset with {len(self.ids)} examples')\n",
        "        logging.info('Scanning mask files to determine unique values')\n",
        "        with Pool() as p:\n",
        "            unique = list(tqdm(\n",
        "                p.imap(partial(unique_mask_values, mask_dir=self.mask_dir, mask_suffix=self.mask_suffix), self.ids),\n",
        "                total=len(self.ids)\n",
        "            ))\n",
        "\n",
        "        self.mask_values = list(sorted(np.unique(np.concatenate(unique), axis=0).tolist()))\n",
        "        logging.info(f'Unique mask values: {self.mask_values}')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ids)\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess(mask_values, pil_img, scale, is_mask):\n",
        "        w, h = pil_img.size\n",
        "        newW, newH = int(scale * w), int(scale * h)\n",
        "        assert newW > 0 and newH > 0, 'Scale is too small, resized images would have no pixel'\n",
        "        pil_img = pil_img.resize((newW, newH), resample=Image.NEAREST if is_mask else Image.BICUBIC)\n",
        "        img = np.asarray(pil_img)\n",
        "\n",
        "        if is_mask:\n",
        "            mask = np.zeros((newH, newW), dtype=np.int64)\n",
        "            for i, v in enumerate(mask_values):\n",
        "                if img.ndim == 2:\n",
        "                    mask[img == v] = i\n",
        "                else:\n",
        "                    mask[(img == v).all(-1)] = i\n",
        "\n",
        "            return mask\n",
        "\n",
        "        else:\n",
        "            if img.ndim == 2:\n",
        "                img = img[np.newaxis, ...]\n",
        "            else:\n",
        "                img = img.transpose((2, 0, 1))\n",
        "\n",
        "            if (img > 1).any():\n",
        "                img = img / 255.0\n",
        "\n",
        "            return img\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        name = self.ids[idx]\n",
        "        mask_file = list(self.mask_dir.glob(name + self.mask_suffix + '.*'))\n",
        "        img_file = list(self.images_dir.glob(name + '.*'))\n",
        "\n",
        "        assert len(img_file) == 1, f'Either no image or multiple images found for the ID {name}: {img_file}'\n",
        "        assert len(mask_file) == 1, f'Either no mask or multiple masks found for the ID {name}: {mask_file}'\n",
        "        mask = load_image(mask_file[0])\n",
        "        img = load_image(img_file[0])\n",
        "\n",
        "        assert img.size == mask.size, \\\n",
        "            f'Image and mask {name} should be the same size, but are {img.size} and {mask.size}'\n",
        "\n",
        "        img = self.preprocess(self.mask_values, img, self.scale, is_mask=False)\n",
        "        mask = self.preprocess(self.mask_values, mask, self.scale, is_mask=True)\n",
        "\n",
        "        return {\n",
        "            'image': torch.as_tensor(img.copy()).float().contiguous(),\n",
        "            'mask': torch.as_tensor(mask.copy()).long().contiguous()\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YTEZu4mOrylM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "\n",
        "def dice_coeff(input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon: float = 1e-6):\n",
        "    # Average of Dice coefficient for all batches, or for a single mask\n",
        "    assert input.size() == target.size()\n",
        "    assert input.dim() == 3 or not reduce_batch_first\n",
        "\n",
        "    sum_dim = (-1, -2) if input.dim() == 2 or not reduce_batch_first else (-1, -2, -3)\n",
        "\n",
        "    inter = 2 * (input * target).sum(dim=sum_dim)\n",
        "    sets_sum = input.sum(dim=sum_dim) + target.sum(dim=sum_dim)\n",
        "    sets_sum = torch.where(sets_sum == 0, inter, sets_sum)\n",
        "\n",
        "    dice = (inter + epsilon) / (sets_sum + epsilon)\n",
        "    return dice.mean()\n",
        "\n",
        "\n",
        "def multiclass_dice_coeff(input: Tensor, target: Tensor, reduce_batch_first: bool = False, epsilon: float = 1e-6):\n",
        "    # Average of Dice coefficient for all classes\n",
        "    return dice_coeff(input.flatten(0, 1), target.flatten(0, 1), reduce_batch_first, epsilon)\n",
        "\n",
        "\n",
        "def dice_loss(input: Tensor, target: Tensor, multiclass: bool = False):\n",
        "    # Dice loss (objective to minimize) between 0 and 1\n",
        "    fn = multiclass_dice_coeff if multiclass else dice_coeff\n",
        "    return 1 - fn(input, target, reduce_batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UFifZafCrY7-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "@torch.inference_mode()\n",
        "def evaluate(net, dataloader, device, amp):\n",
        "    net.eval()\n",
        "    num_val_batches = len(dataloader)\n",
        "    dice_score = 0\n",
        "\n",
        "    # iterate over the validation set\n",
        "    with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n",
        "        for batch in tqdm(dataloader, total=num_val_batches, desc='Validation round', unit='batch', leave=False):\n",
        "            image, mask_true = batch['image'], batch['mask']\n",
        "\n",
        "            # move images and labels to correct device and type\n",
        "            image = image.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
        "            mask_true = mask_true.to(device=device, dtype=torch.long)\n",
        "\n",
        "            # predict the mask\n",
        "            mask_pred = net(image)\n",
        "\n",
        "            if net.n_classes == 1:\n",
        "                assert mask_true.min() >= 0 and mask_true.max() <= 1, 'True mask indices should be in [0, 1]'\n",
        "                mask_pred = (F.sigmoid(mask_pred) > 0.5).float()\n",
        "                # compute the Dice score\n",
        "                dice_score += dice_coeff(mask_pred, mask_true, reduce_batch_first=False)\n",
        "            else:\n",
        "                assert mask_true.min() >= 0 and mask_true.max() < net.n_classes, 'True mask indices should be in [0, n_classes['\n",
        "                # convert to one-hot format\n",
        "                mask_true = F.one_hot(mask_true, net.n_classes).permute(0, 3, 1, 2).float()\n",
        "                mask_pred = F.one_hot(mask_pred.argmax(dim=1), net.n_classes).permute(0, 3, 1, 2).float()\n",
        "                # compute the Dice score, ignoring background\n",
        "                dice_score += multiclass_dice_coeff(mask_pred[:, 1:], mask_true[:, 1:], reduce_batch_first=False)\n",
        "\n",
        "    net.train()\n",
        "    return dice_score / max(num_val_batches, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 22000/22000 [00:01<00:00, 16125.67it/s]\n",
            "100%|██████████| 21978/21978 [00:01<00:00, 18316.90it/s]\n",
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manony-mouse-39621772799264332\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/teamspace/studios/this_studio/wandb/run-20240430_064519-se01adwc</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/anony-mouse-39621772799264332/U-Net/runs/se01adwc' target=\"_blank\">logical-fog-24</a></strong> to <a href='https://wandb.ai/anony-mouse-39621772799264332/U-Net' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/anony-mouse-39621772799264332/U-Net' target=\"_blank\">https://wandb.ai/anony-mouse-39621772799264332/U-Net</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/anony-mouse-39621772799264332/U-Net/runs/se01adwc' target=\"_blank\">https://wandb.ai/anony-mouse-39621772799264332/U-Net/runs/se01adwc</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/20:  50%|████▉     | 10944/22000 [03:40<03:05, 59.73img/s, loss (batch)=1.1] /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.7058, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/20:  99%|█████████▉| 21888/22000 [07:10<00:01, 59.26img/s, loss (batch)=0.122]/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.8782, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/20: 100%|██████████| 22000/22000 [07:32<00:00, 48.64img/s, loss (batch)=0.124]\n",
            "Epoch 2/20:  49%|████▉     | 10880/22000 [03:54<29:00,  6.39img/s, loss (batch)=0.0383]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9484, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/20:  99%|█████████▉| 21824/22000 [07:26<00:27,  6.40img/s, loss (batch)=0.0218]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9608, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/20: 100%|██████████| 22000/22000 [07:30<00:00, 48.80img/s, loss (batch)=0.0242]\n",
            "Epoch 3/20:  49%|████▉     | 10752/22000 [03:51<28:59,  6.47img/s, loss (batch)=0.0175]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9617, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/20:  99%|█████████▊| 21696/22000 [07:22<00:46,  6.49img/s, loss (batch)=0.014] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9703, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/20: 100%|██████████| 22000/22000 [07:28<00:00, 49.01img/s, loss (batch)=0.0141]\n",
            "Epoch 4/20:  48%|████▊     | 10624/22000 [03:48<29:21,  6.46img/s, loss (batch)=0.0123]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9751, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/20:  98%|█████████▊| 21568/22000 [07:21<01:07,  6.42img/s, loss (batch)=0.00954]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9766, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/20: 100%|██████████| 22000/22000 [07:30<00:00, 48.87img/s, loss (batch)=0.0107] \n",
            "Epoch 5/20:  48%|████▊     | 10496/22000 [03:48<30:30,  6.28img/s, loss (batch)=0.0082] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9789, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/20:  97%|█████████▋| 21440/22000 [07:19<01:27,  6.42img/s, loss (batch)=0.00971]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9781, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/20: 100%|██████████| 22000/22000 [07:29<00:00, 48.92img/s, loss (batch)=0.00937]\n",
            "Epoch 6/20:  47%|████▋     | 10368/22000 [03:44<30:11,  6.42img/s, loss (batch)=0.00835]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9821, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/20:  97%|█████████▋| 21312/22000 [07:16<01:47,  6.40img/s, loss (batch)=0.00716]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9833, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/20: 100%|██████████| 22000/22000 [07:29<00:00, 48.97img/s, loss (batch)=0.00704]\n",
            "Epoch 7/20:  47%|████▋     | 10240/22000 [03:42<30:17,  6.47img/s, loss (batch)=0.00829]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9835, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/20:  96%|█████████▋| 21184/22000 [07:16<02:08,  6.37img/s, loss (batch)=0.00758]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9838, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/20: 100%|██████████| 22000/22000 [07:30<00:00, 48.79img/s, loss (batch)=0.00666]\n",
            "Epoch 8/20:  46%|████▌     | 10112/22000 [03:41<31:26,  6.30img/s, loss (batch)=0.0075] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9842, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/20:  96%|█████████▌| 21056/22000 [07:15<02:26,  6.42img/s, loss (batch)=0.00612]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9808, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/20: 100%|██████████| 22000/22000 [07:31<00:00, 48.67img/s, loss (batch)=0.00953]\n",
            "Epoch 9/20:  45%|████▌     | 9984/22000 [03:38<31:05,  6.44img/s, loss (batch)=0.00688]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9824, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/20:  95%|█████████▌| 20928/22000 [07:10<02:44,  6.51img/s, loss (batch)=0.00572]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9865, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/20: 100%|██████████| 22000/22000 [07:29<00:00, 48.98img/s, loss (batch)=0.00564]\n",
            "Epoch 10/20:  45%|████▍     | 9856/22000 [03:36<31:41,  6.39img/s, loss (batch)=0.00566]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9861, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/20:  95%|█████████▍| 20800/22000 [07:09<03:06,  6.42img/s, loss (batch)=0.00532]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9873, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/20: 100%|██████████| 22000/22000 [07:30<00:00, 48.79img/s, loss (batch)=0.00549]\n",
            "Epoch 11/20:  44%|████▍     | 9728/22000 [03:35<32:14,  6.34img/s, loss (batch)=0.00522]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9889, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/20:  94%|█████████▍| 20672/22000 [07:07<03:27,  6.40img/s, loss (batch)=0.00797]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9785, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/20: 100%|██████████| 22000/22000 [07:30<00:00, 48.83img/s, loss (batch)=0.00678]\n",
            "Epoch 12/20:  44%|████▎     | 9600/22000 [03:31<32:17,  6.40img/s, loss (batch)=0.00584]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9852, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/20:  93%|█████████▎| 20544/22000 [07:03<03:45,  6.45img/s, loss (batch)=0.00686]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9862, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/20: 100%|██████████| 22000/22000 [07:29<00:00, 49.00img/s, loss (batch)=0.00756]\n",
            "Epoch 13/20:  43%|████▎     | 9472/22000 [03:28<32:10,  6.49img/s, loss (batch)=0.00519]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9898, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/20:  93%|█████████▎| 20416/22000 [07:01<04:09,  6.34img/s, loss (batch)=0.00561]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9879, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/20: 100%|██████████| 22000/22000 [07:29<00:00, 48.96img/s, loss (batch)=0.00515]\n",
            "Epoch 14/20:  42%|████▏     | 9344/22000 [03:25<33:01,  6.39img/s, loss (batch)=0.00507]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9891, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/20:  92%|█████████▏| 20288/22000 [06:57<04:24,  6.46img/s, loss (batch)=0.00484]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9904, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/20: 100%|██████████| 22000/22000 [07:27<00:00, 49.21img/s, loss (batch)=0.00487]\n",
            "Epoch 15/20:  42%|████▏     | 9216/22000 [03:24<32:46,  6.50img/s, loss (batch)=0.0049] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9912, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/20:  92%|█████████▏| 20160/22000 [06:58<04:48,  6.38img/s, loss (batch)=0.00508]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9911, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/20: 100%|██████████| 22000/22000 [07:29<00:00, 48.89img/s, loss (batch)=0.00506]\n",
            "Epoch 16/20:  41%|████▏     | 9088/22000 [03:21<32:56,  6.53img/s, loss (batch)=0.00491]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9911, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/20:  91%|█████████ | 20032/22000 [06:52<05:04,  6.46img/s, loss (batch)=0.00489]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9896, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/20: 100%|██████████| 22000/22000 [07:26<00:00, 49.30img/s, loss (batch)=0.00576]\n",
            "Epoch 17/20:  41%|████      | 8960/22000 [03:21<34:03,  6.38img/s, loss (batch)=0.00509]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9913, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/20:  90%|█████████ | 19904/22000 [06:54<05:24,  6.45img/s, loss (batch)=0.0047] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9912, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/20: 100%|██████████| 22000/22000 [07:30<00:00, 48.79img/s, loss (batch)=0.00443]\n",
            "Epoch 18/20:  40%|████      | 8832/22000 [03:19<34:03,  6.44img/s, loss (batch)=0.00713]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9857, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/20:  90%|████████▉ | 19776/22000 [06:51<05:47,  6.40img/s, loss (batch)=0.00543]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9873, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/20: 100%|██████████| 22000/22000 [07:29<00:00, 48.89img/s, loss (batch)=0.0078] \n",
            "Epoch 19/20:  40%|███▉      | 8704/22000 [03:16<34:15,  6.47img/s, loss (batch)=0.00521]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9886, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/20:  89%|████████▉ | 19648/22000 [06:48<06:01,  6.51img/s, loss (batch)=0.00499]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9923, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/20: 100%|██████████| 22000/22000 [07:27<00:00, 49.14img/s, loss (batch)=0.00401]\n",
            "Epoch 20/20:  39%|███▉      | 8576/22000 [03:13<34:29,  6.49img/s, loss (batch)=0.0044] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9931, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/20:  89%|████████▊ | 19520/22000 [06:45<06:20,  6.53img/s, loss (batch)=0.00451]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Score tensor(0.9930, device='cuda:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/20: 100%|██████████| 22000/22000 [07:28<00:00, 49.08img/s, loss (batch)=0.00516]\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "from pathlib import Path\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "import wandb\n",
        "\n",
        "dir_img = Path('/teamspace/studios/this_studio/Ragnor/dataset/train_new/image')\n",
        "dir_mask = Path('/teamspace/studios/this_studio/Ragnor/dataset/train_new/label')\n",
        "dir_checkpoint = Path('./checkpoints_0430_3/')\n",
        "\n",
        "dir_val_img = Path('/teamspace/studios/this_studio/Ragnor/dataset/val_new/image')\n",
        "dir_val_mask = Path('/teamspace/studios/this_studio/Ragnor/dataset/val_new/label')\n",
        "\n",
        "def train_model(\n",
        "        model,\n",
        "        device,\n",
        "        epochs: int = 20,\n",
        "        batch_size: int = 64,\n",
        "        learning_rate: float = 1e-5,\n",
        "        val_percent: float = 0.,\n",
        "        save_checkpoint: bool = True,\n",
        "        img_scale: float = 1,\n",
        "        amp: bool = False,\n",
        "        weight_decay: float = 1e-8,\n",
        "        momentum: float = 0.999,\n",
        "        gradient_clipping: float = 1.0,\n",
        "):\n",
        "    # 1. Create dataset\n",
        "\n",
        "    dataset = BasicDataset(dir_img, dir_mask, img_scale)\n",
        "    raw_val_dataset = BasicDataset(dir_val_img, dir_val_mask, img_scale)\n",
        "    val_set, _ = random_split(raw_val_dataset, [0.1, 0.9], generator=torch.Generator().manual_seed(0))\n",
        "    # 2. Split into train / validation partitions\n",
        "    n_train = len(dataset)\n",
        "    n_val = len(val_set)\n",
        "    # train_set, val_set = random_split(dataset, [n_train, n_val], generator=torch.Generator().manual_seed(0))\n",
        "\n",
        "    # 3. Create data loaders\n",
        "    loader_args = dict(batch_size=batch_size, num_workers=os.cpu_count(), pin_memory=True)\n",
        "    train_loader = DataLoader(dataset, shuffle=True, **loader_args)\n",
        "    # train_loader = DataLoader(train_set, shuffle=True, **loader_args)\n",
        "    val_loader = DataLoader(val_set, shuffle=False, drop_last=True, **loader_args)\n",
        "\n",
        "    # (Initialize logging)\n",
        "    experiment = wandb.init(project='U-Net', resume='allow', anonymous='must')\n",
        "    experiment.config.update(\n",
        "        dict(epochs=epochs, batch_size=batch_size, learning_rate=learning_rate,\n",
        "             val_percent=val_percent, save_checkpoint=save_checkpoint, img_scale=img_scale, amp=amp)\n",
        "    )\n",
        "\n",
        "    logging.info(f'''Starting training:\n",
        "        Epochs:          {epochs}\n",
        "        Batch size:      {batch_size}\n",
        "        Learning rate:   {learning_rate}\n",
        "        Training size:   {n_train}\n",
        "        Validation size: {n_val}\n",
        "        Checkpoints:     {save_checkpoint}\n",
        "        Device:          {device.type}\n",
        "        Images scaling:  {img_scale}\n",
        "        Mixed Precision: {amp}\n",
        "    ''')\n",
        "\n",
        "    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-8)\n",
        "    scheduler = OneCycleLR(optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=epochs)  # goal: maximize Dice score\n",
        "    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
        "    criterion = nn.CrossEntropyLoss() if model.n_classes > 1 else nn.BCEWithLogitsLoss()\n",
        "    global_step = 0\n",
        "\n",
        "    # 5. Begin training\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        with tqdm(total=n_train, desc=f'Epoch {epoch}/{epochs}', unit='img') as pbar:\n",
        "            for batch in train_loader:\n",
        "                images, true_masks = batch['image'], batch['mask']\n",
        "\n",
        "                assert images.shape[1] == model.n_channels, \\\n",
        "                    f'Network has been defined with {model.n_channels} input channels, ' \\\n",
        "                    f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n",
        "                    'the images are loaded correctly.'\n",
        "\n",
        "                images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
        "                true_masks = true_masks.to(device=device, dtype=torch.long)\n",
        "\n",
        "                with torch.autocast(device.type if device.type != 'mps' else 'cpu', enabled=amp):\n",
        "                    masks_pred = model(images)\n",
        "                    if model.n_classes == 1:\n",
        "                        loss = criterion(masks_pred.squeeze(1), true_masks.float())\n",
        "                        loss += dice_loss(F.sigmoid(masks_pred.squeeze(1)), true_masks.float(), multiclass=False)\n",
        "                    else:\n",
        "                        loss = criterion(masks_pred, true_masks)\n",
        "                        loss += dice_loss(\n",
        "                            F.softmax(masks_pred, dim=1).float(),\n",
        "                            F.one_hot(true_masks, model.n_classes).permute(0, 3, 1, 2).float(),\n",
        "                            multiclass=True\n",
        "                        )\n",
        "\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                grad_scaler.scale(loss).backward()\n",
        "                grad_scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), gradient_clipping)\n",
        "                grad_scaler.step(optimizer)\n",
        "                grad_scaler.update()\n",
        "\n",
        "                pbar.update(images.shape[0])\n",
        "                global_step += 1\n",
        "                epoch_loss += loss.item()\n",
        "                experiment.log({\n",
        "                    'train loss': loss.item(),\n",
        "                    'step': global_step,\n",
        "                    'epoch': epoch\n",
        "                })\n",
        "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
        "\n",
        "                # Evaluation round\n",
        "                division_step = (n_train // (2 * batch_size))\n",
        "                if division_step > 0:\n",
        "                    if global_step % division_step == 0:\n",
        "                        histograms = {}\n",
        "                        for tag, value in model.named_parameters():\n",
        "                            tag = tag.replace('/', '.')\n",
        "                            if not (torch.isinf(value) | torch.isnan(value)).any():\n",
        "                                histograms['Weights/' + tag] = wandb.Histogram(value.data.cpu())\n",
        "                            if not (torch.isinf(value.grad) | torch.isnan(value.grad)).any():\n",
        "                                histograms['Gradients/' + tag] = wandb.Histogram(value.grad.data.cpu())\n",
        "                        val_score = evaluate(model, val_loader, device, amp)\n",
        "                        print(\"Val Score\", val_score)\n",
        "                        scheduler.step(val_score)\n",
        "\n",
        "                        logging.info('Validation Dice score: {}'.format(val_score))\n",
        "                        try:\n",
        "                            experiment.log({\n",
        "                                'learning rate': optimizer.param_groups[0]['lr'],\n",
        "                                'validation Dice': val_score,\n",
        "                                'images': wandb.Image(images[0].cpu()),\n",
        "                                'masks': {\n",
        "                                    'true': wandb.Image(true_masks[0].float().cpu()),\n",
        "                                    'pred': wandb.Image(masks_pred.argmax(dim=1)[0].float().cpu()),\n",
        "                                },\n",
        "                                'step': global_step,\n",
        "                                'epoch': epoch,\n",
        "                                **histograms\n",
        "                            })\n",
        "                        except:\n",
        "                            pass\n",
        "\n",
        "        if save_checkpoint:\n",
        "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
        "            state_dict = model.state_dict()\n",
        "            state_dict['mask_values'] = dataset.mask_values\n",
        "            torch.save(state_dict, str(dir_checkpoint / 'checkpoint_epoch{}.pth'.format(epoch)))\n",
        "            logging.info(f'Checkpoint {epoch} saved!')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Change here to adapt to your data\n",
        "    # n_channels=3 for RGB images\n",
        "    # n_classes is the number of probabilities you want to get per pixel\n",
        "    model = UNet(n_channels=3, n_classes=49, bilinear=False)\n",
        "    model = model.to(memory_format=torch.channels_last)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    logging.info(f'Network:\\n'\n",
        "                 f'\\t{model.n_channels} input channels\\n'\n",
        "                 f'\\t{model.n_classes} output channels (classes)\\n'\n",
        "                 f'\\t{\"Bilinear\" if model.bilinear else \"Transposed conv\"} upscaling')\n",
        "\n",
        "    model.to(device=device)\n",
        "    train_model(model, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 22000/22000 [00:01<00:00, 18456.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A \n",
            "B \n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "from pathlib import Path\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from tqdm import tqdm\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "import wandb\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dir_img = Path('/teamspace/studios/this_studio/Ragnor/dataset/train_new/image')\n",
        "dir_mask = Path('/teamspace/studios/this_studio/Ragnor/dataset/train_new/label')\n",
        "dir_checkpoint = Path('./checkpoints/')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    dataset = BasicDataset(dir_img, dir_mask, 0.5)\n",
        "    loader_args = dict(batch_size=8, num_workers=os.cpu_count(), pin_memory=True)\n",
        "    print(\"A \")\n",
        "    train_loader = DataLoader(dataset, shuffle=True, **loader_args)\n",
        "    print(\"B \")\n",
        "    for batch in train_loader:\n",
        "        print(\"C \")\n",
        "        images, true_masks = batch['image'], batch['mask']\n",
        "        print(\"Image: \",images.shape)\n",
        "        print(\"Mask: \",true_masks.shape)\n",
        "        img = images[1,:,:,:]\n",
        "        mask = true_masks[1,:,:]\n",
        "        plt.figure(figsize=(10, 5))\n",
        "            \n",
        "        plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st subplot\n",
        "        plt.imshow(img.permute(1,2,0))\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Plot the second image\n",
        "        plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd subplot\n",
        "        plt.imshow(mask)\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb) (5.9.8)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.0.1-py2.py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: PyYAML in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb) (68.2.2)\n",
            "Collecting appdirs>=1.4.3 (from wandb)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from wandb) (4.23.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /system/conda/miniconda3/envs/cloudspace/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.0.1-py2.py3-none-any.whl (266 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: appdirs, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.43 appdirs-1.4.4 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-2.0.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install wandb"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
