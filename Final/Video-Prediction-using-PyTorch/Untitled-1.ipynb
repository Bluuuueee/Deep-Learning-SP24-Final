{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lightning.pytorch.utilities.types import EVAL_DATALOADERS\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import lightning as pl\n",
    "from lightning import Trainer\n",
    "from multiprocessing import Process\n",
    "\n",
    "from utils.start_tensorboard import run_tensorboard\n",
    "from models.seq2seq_ConvLSTM import EncoderDecoderConvLSTM\n",
    "from data.MovingMNIST import MovingMNIST\n",
    "from data.MaskDataset import MaskDataset\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import argparse\n",
    "import numpy as np\n",
    "from main import MovingMNIST, MovingMNISTLightning\n",
    "from scipy.ndimage import zoom\n",
    "from tqdm import tqdm \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--lr', default=1e-4, type=float, help='learning rate')\n",
    "parser.add_argument('--beta_1', type=float, default=0.9, help='decay rate 1')\n",
    "parser.add_argument('--beta_2', type=float, default=0.98, help='decay rate 2')\n",
    "parser.add_argument('--batch_size', default=12, type=int, help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=600, help='number of epochs to train for')\n",
    "parser.add_argument('--use_amp', default=False, type=bool, help='mixed-precision training')\n",
    "parser.add_argument('--n_gpus', type=int, default=1, help='number of GPUs')\n",
    "parser.add_argument('--n_hidden_dim', type=int, default=96, help='number of hidden dim for ConvLSTM layers')\n",
    "\n",
    "opt = parser.parse_args()\n",
    "\n",
    "\n",
    "def testOnMasks(model, dir=\"D:/GameCenter/DeepLearning/Final/dataset/train\"):\n",
    "    all_videos = os.listdir(dir)\n",
    "    cnt = len(all_videos)\n",
    "    \n",
    "    for i in tqdm(range(cnt)):\n",
    "        f = os.path.join(dir, all_videos[i], \"mask.npy\")\n",
    "        mask_raw = np.load(f)\n",
    "        mask = mask_raw[0:11, :,:]\n",
    "        mask_flat = mask.flatten()\n",
    "        count = np.bincount(mask.flatten(), minlength=32)\n",
    "        non_zero_indices = np.nonzero(count)[0]\n",
    "        if non_zero_indices.shape[0] > 9:\n",
    "            # print(\"!!!\", i, \"  !  \", non_zero_indices)\n",
    "            non_zero_indices = non_zero_indices[0:9].copy()\n",
    "        permutation = np.random.permutation(np.arange(1, 9))\n",
    "        permutation = np.concatenate(([0], permutation))\n",
    "\n",
    "        value_to_index = {value: permutation[idx] for idx, value in enumerate(non_zero_indices)}\n",
    "        index_to_value = {permutation[idx]: value for idx, value in enumerate(non_zero_indices)}\n",
    "        mask_p = np.array([value_to_index.get(item, 0) for item in mask_flat])\n",
    "\n",
    "        mask_p = mask_p.reshape(mask.shape)\n",
    "        one_hot = np.eye(9)[mask_p]\n",
    "        resized = np.zeros((11, 40, 60, 9))\n",
    "        for k in range(11):\n",
    "            for j in range(9):\n",
    "                resized[k, :, :, j] = zoom(one_hot[k, :, :, j], (0.25, 0.25))\n",
    "        resized = np.float32(resized)\n",
    "        input = torch.tensor(resized).unsqueeze(0).permute(0, 1, 4, 2, 3)\n",
    "        answer = model.forward(input)\n",
    "        answer = answer.squeeze(0)[-1,:,:,:].argmax(dim=-1).type(torch.IntTensor).numpy()\n",
    "        print(\"N-1:\", np.nonzero(np.bincount(answer.flatten(), minlength=32))[0])\n",
    "        answer_flat = answer.flatten()\n",
    "        print(value_to_index)\n",
    "        print(index_to_value)\n",
    "        answer_r = np.array([index_to_value.get(item, 0) for item in answer_flat])\n",
    "        answer_r = answer_r.reshape(answer.shape)\n",
    "        answer_r = np.repeat(answer_r, repeats=4, axis=0)\n",
    "        answer_r = np.repeat(answer_r, repeats=4, axis=1)\n",
    "        print(\"N0:\", non_zero_indices)\n",
    "        print(\"N1:\", np.nonzero(np.bincount(answer_r.flatten(), minlength=32))[0])\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st subplot\n",
    "        plt.imshow(answer_r)\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Plot the second image\n",
    "        plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd subplot\n",
    "        plt.imshow(mask_raw[-1,:,:])\n",
    "        plt.axis('off')\n",
    "  \n",
    "\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    conv_lstm_model = EncoderDecoderConvLSTM(nf=opt.n_hidden_dim, in_chan=9)\n",
    "    model = MovingMNISTLightning.load_from_checkpoint(\"epoch=164-step=13836.ckpt\", model=conv_lstm_model)\n",
    "    testOnMasks(model=model)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
